{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def parse_metrics(command):\n",
    "    # Run the command using subprocess in Jupyter\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        # print(\"Output:\\n\", result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error occurred:\\n\", e.stderr)\n",
    "\n",
    "    # Split the output into lines\n",
    "    output_lines = result.stdout.strip().split('\\n')\n",
    "    # print(output_lines)\n",
    "\n",
    "    # Iterate over the lines to find metrics\n",
    "    for i, line in enumerate(output_lines):\n",
    "        if 'Metrics before applying QB-Norm' in line:\n",
    "            # The next line contains the metrics dictionary\n",
    "            if i + 1 < len(output_lines):\n",
    "                metrics_line = output_lines[i + 1].strip()\n",
    "                try:\n",
    "                    metrics_before = ast.literal_eval(metrics_line)\n",
    "                except (SyntaxError, ValueError):\n",
    "                    print(f\"Could not parse metrics before at line {i + 1}: {metrics_line}\")\n",
    "        elif 'Metrics after QB-Norm' in line:\n",
    "            # The next line contains the metrics dictionary\n",
    "            if i + 1 < len(output_lines):\n",
    "                metrics_line = output_lines[i + 1].strip()\n",
    "                try:\n",
    "                    metrics_after = ast.literal_eval(metrics_line)\n",
    "                except (SyntaxError, ValueError):\n",
    "                    print(f\"Could not parse metrics after at line {i + 1}: {metrics_line}\")\n",
    "\n",
    "    # # Now you have lists of metrics dictionaries\n",
    "    # print(\"Metrics Before QB-Norm:\", metrics_before_list)\n",
    "    # print(\"Metrics After QB-Norm:\", metrics_after_list)\n",
    "\n",
    "    # Save the metrics into a variable\n",
    "    metrics = {\n",
    "        'before': metrics_before,\n",
    "        'after': metrics_after\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def execute_dynamic_inverted_softmax(test_file_path, train_file_path, adv_test_similarity_path, adv_train_similarity_path, gt_idx_path, out_dir):\n",
    "    out_dir=out_dir+\"/output_cache\"\n",
    "    # Load data from file\n",
    "    data = np.load(test_file_path, allow_pickle=True)  # Load the data as a NumPy array\n",
    "    train_data = np.load(train_file_path, allow_pickle=True)  # Load the data as a NumPy array\n",
    "    # Load adversarial similarity matrices\n",
    "    adv_test_similarity_matrices = np.load(adv_test_similarity_path, allow_pickle=True)\n",
    "    adv_train_similarity_matrices = np.load(adv_train_similarity_path, allow_pickle=True)\n",
    "\n",
    "    gt_idx=np.load(gt_idx_path, allow_pickle=True)\n",
    "    \n",
    "    # Create temp directory if it doesn't exist\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    gt_metrics = {}\n",
    "    adv_metrics = {}\n",
    "    # Iterate over adversarial matrices, modify data, save with different names, and execute command\n",
    "    for i, adv in enumerate(tqdm(adv_test_similarity_matrices[:100])):\n",
    "        # print(\"Adv shape:\", adv.shape)\n",
    "        test_data_temp = data.copy()\n",
    "        test_data_temp = np.column_stack((test_data_temp, adv.flatten()))        \n",
    "        # Save the modified data to a new file with different names in temp directory\n",
    "        modified_file_path = f'{out_dir}/modified-test-images-texts-seed0-{i}.pkl'\n",
    "        with open(modified_file_path, 'wb') as f:\n",
    "            pkl.dump(test_data_temp, f)\n",
    "        # print(f\"Modified data saved to {modified_file_path}\")\n",
    "\n",
    "        train_data_temp = train_data.copy()\n",
    "        flattened_column = adv_train_similarity_matrices[i].flatten()\n",
    "        train_data_temp = np.column_stack((train_data_temp, flattened_column))\n",
    "        # save the modified train data to a new file with different names in temp directory\n",
    "        modified_train_file_path = f'{out_dir}/modified-train-images-texts-seed0-{i}.pkl'\n",
    "        with open(modified_train_file_path, 'wb') as f:\n",
    "            pkl.dump(train_data_temp, f)\n",
    "\n",
    "        num_queries, num_vids = test_data_temp.shape\n",
    "        queries_per_video =  math.ceil(num_queries / num_vids)\n",
    "        adv_idx = np.array([\n",
    "            [num_vids * (ii + jj * queries_per_video) + num_vids - 1 for ii in range(queries_per_video)]\n",
    "            for jj in range(num_vids-1)\n",
    "        ])\n",
    "\n",
    "        adv_idx_path = f'{out_dir}/adv_idx.pkl'\n",
    "        with open(adv_idx_path, 'wb') as f:\n",
    "            pkl.dump(adv_idx, f)\n",
    "        # print(f\"adv_idx saved to {adv_idx_path}\")\n",
    "\n",
    "        modified_gt_index = gt_idx.copy()\n",
    "        temp_shape = modified_gt_index.shape\n",
    "        modified_gt_index = modified_gt_index.flatten() + np.arange(modified_gt_index.size)\n",
    "        modified_gt_index = modified_gt_index.reshape(temp_shape)\n",
    "\n",
    "        modified_gt_index_path=f'{out_dir}/modified_gt_idx-{i}.pkl'\n",
    "        with open(modified_gt_index_path, 'wb') as f:\n",
    "            pkl.dump(modified_gt_index, f)\n",
    "        # print(f\"modified_gt_idx saved to {modified_gt_index_path}\")\n",
    "\n",
    "        # Define the command and arguments for each modified data file\n",
    "        gt_command = [\n",
    "            'python', 'dynamic_inverted_softmax.py',\n",
    "            '--sims_train_test_path', modified_train_file_path,\n",
    "            '--sims_test_path', modified_file_path,\n",
    "            '--gt_idx_path', modified_gt_index_path\n",
    "        ]\n",
    "\n",
    "        adv_command = [\n",
    "            'python', 'dynamic_inverted_softmax.py',\n",
    "            '--sims_train_test_path', modified_train_file_path,\n",
    "            '--sims_test_path', modified_file_path,\n",
    "            '--gt_idx_path', adv_idx_path\n",
    "        ]\n",
    "        \n",
    "        # Run the command\n",
    "        gt_metrics[i]=parse_metrics(gt_command)\n",
    "        print(gt_metrics[i])\n",
    "\n",
    "        adv_metrics[i]=parse_metrics(adv_command)\n",
    "        print(adv_metrics[i])\n",
    "        \n",
    "        # save the metrics to a file\n",
    "        with open(f'{out_dir}/gt_metrics.pkl', 'wb') as f:\n",
    "            pkl.dump(gt_metrics, f)\n",
    "        with open(f'{out_dir}/adv_metrics.pkl', 'wb') as f:\n",
    "            pkl.dump(adv_metrics, f)\n",
    "\n",
    "        # Remove the modified data files\n",
    "        os.remove(modified_file_path)\n",
    "        \n",
    "    return gt_metrics, adv_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (500, 5000)\n",
      "Train data shape: (50, 5000)\n",
      "Adv test similarity matrices shape: (1, 500)\n",
      "Adv train similarity matrices shape: (1, 50)\n",
      "GT index shape: (500, 5)\n",
      "Error occurred:\n",
      " Traceback (most recent call last):\n",
      "  File \"/share/shmatikov/tingwei/Desktop/hubness/adversarial_hubness/qb-norm/dynamic_inverted_softmax.py\", line 78, in <module>\n",
      "    main()\n",
      "  File \"/share/shmatikov/tingwei/Desktop/hubness/adversarial_hubness/qb-norm/dynamic_inverted_softmax.py\", line 66, in main\n",
      "    print(metric.t2v_metrics(test_test, gt_idx, test_query_masks))\n",
      "  File \"/share/shmatikov/tingwei/Desktop/hubness/adversarial_hubness/qb-norm/metric.py\", line 48, in t2v_metrics\n",
      "    gt_dists = dists.reshape(-1)[gt_idx.reshape(-1)]\n",
      "IndexError: index 2500100 is out of bounds for axis 0 with size 2500000\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'result' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     32\u001b[0m command \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_inverted_softmax.py\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--sims_train_test_path\u001b[39m\u001b[38;5;124m'\u001b[39m, train_file_path,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--sims_test_path\u001b[39m\u001b[38;5;124m'\u001b[39m, test_file_path,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--gt_idx_path\u001b[39m\u001b[38;5;124m'\u001b[39m, gt_idx_path\n\u001b[1;32m     37\u001b[0m ]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Parse the metrics\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mparse_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMertrics for original data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mparse_metrics\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Split the output into lines\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m output_lines \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(output_lines)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over the lines to find metrics\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(output_lines):\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'result' referenced before assignment"
     ]
    }
   ],
   "source": [
    "out_dir = '../outputs/mscoco/imagebind/temp/'\n",
    "test_file_path = f'{out_dir}test_similarity_matrix.pkl'\n",
    "train_file_path = f'{out_dir}train_similarity_matrix.pkl'\n",
    "adv_test_similarity_path = f'{out_dir}adv_test_similarity_matrix.pkl'\n",
    "adv_train_similarity_path = f'{out_dir}adv_train_similarity_matrix.pkl'\n",
    "gt_idx_path='../outputs/mscoco/gt_idx.pkl'\n",
    "\n",
    "# print the shape of the similarity matrices\n",
    "test_data = np.load(test_file_path, allow_pickle=True)\n",
    "train_data = np.load(train_file_path, allow_pickle=True)\n",
    "adv_test_similarity_matrices = np.load(adv_test_similarity_path, allow_pickle=True)\n",
    "adv_train_similarity_matrices = np.load(adv_train_similarity_path, allow_pickle=True)\n",
    "gt_idx=np.load(gt_idx_path, allow_pickle=True)\n",
    "\n",
    "# save the first 500 rows of gt_idx\n",
    "gt_idx=gt_idx[:500]\n",
    "with open(gt_idx_path, 'wb') as f:\n",
    "    pkl.dump(gt_idx, f)\n",
    "gt_idx=np.load(gt_idx_path, allow_pickle=True)\n",
    "\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Adv test similarity matrices shape:\", adv_test_similarity_matrices.shape)\n",
    "print(\"Adv train similarity matrices shape:\", adv_train_similarity_matrices.shape)\n",
    "print(\"GT index shape:\", gt_idx.shape)\n",
    "\n",
    "out_dir='output/mscoco/imagebind/temp/'\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Define the command and arguments\n",
    "command = [\n",
    "    'python', 'dynamic_inverted_softmax.py',\n",
    "    '--sims_train_test_path', train_file_path,\n",
    "    '--sims_test_path', test_file_path,\n",
    "    '--gt_idx_path', gt_idx_path\n",
    "]\n",
    "\n",
    "# Parse the metrics\n",
    "metrics = parse_metrics(command)\n",
    "print(\"Mertrics for original data:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb66b7b1b00421d91dd4d1b20c2ed7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'before': {'R1': 48.4, 'R5': 72.7, 'R10': 81.0, 'R50': 95.3, 'MedR': 2.0, 'MeanR': 13.8, 'geometric_mean_R1-R5-R10': 65.8, 'MeanA': 0.311}, 'after': {'R1': 49.9, 'R5': 73.8, 'R10': 82.3, 'R50': 95.7, 'MedR': 2.0, 'MeanR': 13.3, 'geometric_mean_R1-R5-R10': 67.2, 'MeanA': 0.131}}\n",
      "{'before': {'R1': 0.0, 'R5': 0.0, 'R10': 0.0, 'R50': 0.3, 'MedR': 3496.5, 'MeanR': 3025.6, 'geometric_mean_R1-R5-R10': 0.0, 'MeanA': -0.025}, 'after': {'R1': 0.0, 'R5': 0.0, 'R10': 0.1, 'R50': 0.9, 'MedR': 2882.0, 'MeanR': 2768.4, 'geometric_mean_R1-R5-R10': 0.0, 'MeanA': -0.005}}\n",
      "{'before': {'R1': 48.4, 'R5': 72.7, 'R10': 81.0, 'R50': 95.3, 'MedR': 2.0, 'MeanR': 13.8, 'geometric_mean_R1-R5-R10': 65.8, 'MeanA': 0.311}, 'after': {'R1': 49.9, 'R5': 73.8, 'R10': 82.3, 'R50': 95.7, 'MedR': 2.0, 'MeanR': 13.3, 'geometric_mean_R1-R5-R10': 67.2, 'MeanA': 0.131}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gt_metrics, adv_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_dynamic_inverted_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv_test_similarity_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv_train_similarity_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_idx_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 129\u001b[0m, in \u001b[0;36mexecute_dynamic_inverted_softmax\u001b[0;34m(test_file_path, train_file_path, adv_test_similarity_path, adv_train_similarity_path, gt_idx_path, out_dir)\u001b[0m\n\u001b[1;32m    126\u001b[0m gt_metrics[i]\u001b[38;5;241m=\u001b[39mparse_metrics(gt_command)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(gt_metrics[i])\n\u001b[0;32m--> 129\u001b[0m adv_metrics[i]\u001b[38;5;241m=\u001b[39m\u001b[43mparse_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43madv_command\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(adv_metrics[i])\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# save the metrics to a file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m, in \u001b[0;36mparse_metrics\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_metrics\u001b[39m(command):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Run the command using subprocess in Jupyter\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# print(\"Output:\\n\", result.stdout)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/adversarial_illusions/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/envs/adversarial_illusions/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/adversarial_illusions/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adversarial_illusions/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gt_metrics, adv_metrics = execute_dynamic_inverted_softmax(test_file_path, train_file_path, adv_test_similarity_path, adv_train_similarity_path, gt_idx_path, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stats: {'R1': {'average': 87.7, 'std_dev': 2.7}, 'R5': {'average': 98.5, 'std_dev': 0.5}, 'R10': {'average': 99.2, 'std_dev': 0.3}, 'R50': {'average': 99.9, 'std_dev': 0.1}, 'MedR': {'average': 1.0, 'std_dev': 0.0}, 'MeanR': {'average': 1.6, 'std_dev': 0.2}, 'geometric_mean_R1-R5-R10': {'average': 95.0, 'std_dev': 1.2}, 'MeanA': {'average': 0.4, 'std_dev': 0.0}}\n",
      "After stats: {'R1': {'average': 0.0, 'std_dev': 0.0}, 'R5': {'average': 9.8, 'std_dev': 1.8}, 'R10': {'average': 10.4, 'std_dev': 1.9}, 'R50': {'average': 10.9, 'std_dev': 2.0}, 'MedR': {'average': 700.6, 'std_dev': 52.9}, 'MeanR': {'average': 1059.1, 'std_dev': 83.0}, 'geometric_mean_R1-R5-R10': {'average': 0.0, 'std_dev': 0.0}, 'MeanA': {'average': 0.0, 'std_dev': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the metrics from the file\n",
    "with open(f'{out_dir}/gt_metrics.pkl', 'rb') as f:\n",
    "    temp_gt_metrics = pkl.load(f)\n",
    "with open(f'{out_dir}/adv_metrics.pkl', 'rb') as f:\n",
    "    temp_adv_metrics = pkl.load(f)\n",
    "# print(temp_gt_metrics)\n",
    "data=temp_adv_metrics\n",
    "\n",
    "# Initialize dictionaries to hold lists of metric values across entries\n",
    "metrics_before = {key: [] for key in data[0]['before']}\n",
    "metrics_after = {key: [] for key in data[0]['after']}\n",
    "\n",
    "# Collect all metric values for each metric type across all entries\n",
    "for entry in data.values():\n",
    "    for metric, value in entry['before'].items():\n",
    "        metrics_before[metric].append(value)\n",
    "    for metric, value in entry['after'].items():\n",
    "        metrics_after[metric].append(value)\n",
    "\n",
    "# Function to calculate mean and standard deviation\n",
    "def calculate_stats(metrics_dict):\n",
    "    stats = {}\n",
    "    for metric, values in metrics_dict.items():\n",
    "        avg = round(np.mean(values), 1)\n",
    "        std_dev = round(np.std(values), 1)\n",
    "        stats[metric] = {'average': avg, 'std_dev': std_dev}\n",
    "    return stats\n",
    "\n",
    "# Calculate stats for 'before' and 'after'\n",
    "before_stats = calculate_stats(metrics_before)\n",
    "after_stats = calculate_stats(metrics_after)\n",
    "\n",
    "print(\"Before stats:\", before_stats)\n",
    "print(\"After stats:\", after_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.02506852, 1.00937605, 1.01661122, 1.01842856, 1.0152241 ,\n",
       "       1.02379477, 1.032305  , 1.03086638, 1.02125967, 1.01448226,\n",
       "       1.01659763, 1.01777983, 0.99880058, 1.02198017, 1.02198994,\n",
       "       1.02657175, 1.00587475, 1.02177978, 1.0246228 , 1.01310778,\n",
       "       1.01104212, 1.03203046, 1.01406276, 0.99049538, 1.01360726,\n",
       "       1.01694167, 1.02484775, 1.01124406, 1.01969612, 1.01337957,\n",
       "       1.02257276, 1.00904822, 1.01691687, 1.02157831, 1.0207634 ,\n",
       "       1.01444888, 1.03035331, 1.0190047 , 1.01873159, 1.0231632 ,\n",
       "       1.01450944, 1.01217473, 1.02775824, 0.99926865, 1.01563632,\n",
       "       1.01016152, 1.02739167, 1.01601613, 1.0235157 , 1.02003384,\n",
       "       1.01785684, 1.0214144 , 1.0276804 , 1.00705564, 1.01561201,\n",
       "       1.01493764, 1.0208658 , 1.0320251 , 1.01928997, 1.02273917,\n",
       "       1.01815546, 1.02846932, 1.03346789, 1.0216434 , 1.01207542,\n",
       "       1.01682591, 1.01468182, 1.01393974, 1.00750697, 1.02121651,\n",
       "       1.00923097, 1.00835407, 1.01207459, 1.01487863, 1.01979947,\n",
       "       1.02250612, 1.02363431, 1.00877428, 1.02135372, 1.01733708,\n",
       "       1.01639402, 1.02193773, 1.00826168, 1.01564133, 1.01474118,\n",
       "       1.01515031, 1.01853752, 1.02598119, 1.01219344, 1.02191186,\n",
       "       1.0111922 , 1.01518869, 1.02176189, 1.02241158, 1.01050985,\n",
       "       1.02782393, 1.02132356, 1.01770985, 1.01464701, 1.00737751])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/share/shmatikov/tingwei/Desktop/hubness/adversarial_hubness/outputs/mscoco/imagebind/evasion_100/adv_loss.npy')s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_illusions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
