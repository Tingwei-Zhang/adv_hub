{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def parse_metrics(command):\n",
    "    # Run the command using subprocess in Jupyter\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        # print(\"Output:\\n\", result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error occurred:\\n\", e.stderr)\n",
    "\n",
    "    # Split the output into lines\n",
    "    output_lines = result.stdout.strip().split('\\n')\n",
    "    # print(output_lines)\n",
    "\n",
    "    metrics_before, metrics_after = None, None\n",
    "    # Iterate over the lines to find metrics\n",
    "    for i, line in enumerate(output_lines):\n",
    "        if 'Metrics before applying QB-Norm' in line:\n",
    "            # The next line contains the metrics dictionary\n",
    "            if i + 1 < len(output_lines):\n",
    "                metrics_line = output_lines[i + 1].strip()\n",
    "                try:\n",
    "                    metrics_before = ast.literal_eval(metrics_line)\n",
    "                except (SyntaxError, ValueError):\n",
    "                    print(f\"Could not parse metrics before at line {i + 1}: {metrics_line}\")\n",
    "        elif 'Metrics after QB-Norm' in line:\n",
    "            # The next line contains the metrics dictionary\n",
    "            if i + 1 < len(output_lines):\n",
    "                metrics_line = output_lines[i + 1].strip()\n",
    "                try:\n",
    "                    metrics_after = ast.literal_eval(metrics_line)\n",
    "                except (SyntaxError, ValueError):\n",
    "                    print(f\"Could not parse metrics after at line {i + 1}: {metrics_line}\")\n",
    "\n",
    "    # Save the metrics into a variable\n",
    "    metrics = {\n",
    "        'before': metrics_before,\n",
    "        'after': metrics_after\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def execute_dynamic_inverted_softmax(test_file_path, adv_test_similarity_path, gt_idx_path, out_dir):\n",
    "    temp_out_dir=out_dir+\"/output_cache\"\n",
    "    # Load data from file\n",
    "    data = np.load(test_file_path, allow_pickle=True)  # Load the data as a NumPy array\n",
    "    # Load adversarial similarity matrices\n",
    "    adv_test_similarity_matrices = np.load(adv_test_similarity_path, allow_pickle=True).T\n",
    "    gt_idx=np.load(gt_idx_path, allow_pickle=True)\n",
    "    # Create temp directory if it doesn't exist\n",
    "    os.makedirs(temp_out_dir, exist_ok=True)\n",
    "    \n",
    "    gt_metrics = {}\n",
    "    adv_metrics = {}\n",
    "    # Iterate over adversarial matrices, modify data, save with different names, and execute command\n",
    "    for i, adv in enumerate(tqdm(adv_test_similarity_matrices[:100])):\n",
    "        # print(\"Adv shape:\", adv.shape)\n",
    "        test_data_temp = data.copy()\n",
    "        # print(\"Test data shape:\", test_data_temp.shape)\n",
    "        # print(\"Adv shape:\", adv.shape)\n",
    "        test_data_temp = np.column_stack((test_data_temp, adv.flatten()))        \n",
    "        # Save the modified data to a new file with different names in temp directory\n",
    "        modified_file_path = f'{temp_out_dir}/modified-test-images-texts-seed0-{i}.pkl'\n",
    "        with open(modified_file_path, 'wb') as f:\n",
    "            pkl.dump(test_data_temp, f)\n",
    "        # print(f\"Modified data saved to {modified_file_path}\")\n",
    "\n",
    "\n",
    "        num_queries, num_vids = test_data_temp.shape\n",
    "        adv_idx = np.array([\n",
    "            num_vids * (i+1) - 1 for i in range(num_queries)\n",
    "        ])\n",
    "\n",
    "        adv_idx_path = f'{temp_out_dir}/adv_idx.pkl'\n",
    "        with open(adv_idx_path, 'wb') as f:\n",
    "            pkl.dump(adv_idx, f)\n",
    "        # print(f\"adv_idx saved to {adv_idx_path}\")\n",
    "\n",
    "        modified_gt_index = gt_idx.copy()\n",
    "        temp_shape = modified_gt_index.shape\n",
    "        modified_gt_index = modified_gt_index.flatten() + np.arange(modified_gt_index.size)\n",
    "        modified_gt_index = modified_gt_index.reshape(temp_shape)\n",
    "\n",
    "        modified_gt_index_path=f'{temp_out_dir}/modified_gt_idx-{i}.pkl'\n",
    "        with open(modified_gt_index_path, 'wb') as f:\n",
    "            pkl.dump(modified_gt_index, f)\n",
    "        # print(f\"modified_gt_idx saved to {modified_gt_index_path}\")\n",
    "\n",
    "        # Define the command and arguments for each modified data file\n",
    "        gt_command = [\n",
    "            'python', 'dynamic_inverted_softmax.py',\n",
    "            '--sims_test_path', modified_file_path,\n",
    "            '--gt_idx_path', modified_gt_index_path\n",
    "        ]\n",
    "\n",
    "        adv_command = [\n",
    "            'python', 'dynamic_inverted_softmax.py',\n",
    "            '--sims_test_path', modified_file_path,\n",
    "            '--gt_idx_path', adv_idx_path\n",
    "        ]\n",
    "        \n",
    "        # Run the command\n",
    "        gt_metrics[i]=parse_metrics(gt_command)\n",
    "        # print(gt_metrics[i])\n",
    "\n",
    "        adv_metrics[i]=parse_metrics(adv_command)\n",
    "        # print(adv_metrics[i])\n",
    "        \n",
    "        # save the metrics to a file\n",
    "        with open(f'{out_dir}/gt_metrics.pkl', 'wb') as f:\n",
    "            pkl.dump(gt_metrics, f)\n",
    "        with open(f'{out_dir}/adv_metrics.pkl', 'wb') as f:\n",
    "            pkl.dump(adv_metrics, f)\n",
    "\n",
    "        # Remove the modified data files\n",
    "        # os.remove(modified_file_path)\n",
    "        \n",
    "    return gt_metrics, adv_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (743, 743)\n",
      "Adv test similarity matrices shape: (743, 100)\n",
      "gt_idx shape: (743,)\n",
      "Mertrics for original data:\n",
      "{'before': {'R1': 6.2, 'R3': 14.9, 'R5': 20.7, 'R10': 31.8, 'R50': 61.5, 'MedR': 27.0, 'MeanR': 95.4, 'geometric_mean_R1-R5-R10': 16.0, 'MeanA': 0.085}, 'after': None}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0482ebc23c704dd08a4c2f317e98163c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_dir = '../outputs/audiocap/audioclip'\n",
    "test_file_path = f'{out_dir}/test_similarity_matrix_fixed.pkl'\n",
    "adv_test_similarity_path = f'{out_dir}/adv_test_similarity_matrix.pkl'\n",
    "gt_idx_path='../outputs/audiocap/gt_idx.pkl'\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# print the shape of the similarity matrices\n",
    "test_data = np.load(test_file_path, allow_pickle=True)\n",
    "adv_test_similarity_matrices = np.load(adv_test_similarity_path, allow_pickle=True)\n",
    "gt_idx=np.load(gt_idx_path, allow_pickle=True)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Adv test similarity matrices shape:\", adv_test_similarity_matrices.shape)\n",
    "print(\"gt_idx shape:\", gt_idx.shape)\n",
    "\n",
    "# Define the command and arguments\n",
    "command = [\n",
    "    'python', 'dynamic_inverted_softmax.py',\n",
    "    '--sims_test_path', test_file_path,\n",
    "    '--gt_idx_path', gt_idx_path\n",
    "]\n",
    "\n",
    "# Parse the metrics\n",
    "metrics = parse_metrics(command)\n",
    "print(\"Mertrics for original data:\")\n",
    "print(metrics)\n",
    "\n",
    "gt_metrics, adv_metrics = execute_dynamic_inverted_softmax(test_file_path, adv_test_similarity_path, gt_idx_path, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt stats: {'R1': {'average': 2.4, 'std_dev': 0.8}, 'R3': {'average': 11.7, 'std_dev': 0.3}, 'R5': {'average': 18.8, 'std_dev': 0.3}, 'R10': {'average': 30.6, 'std_dev': 0.2}, 'R50': {'average': 61.2, 'std_dev': 0.0}, 'MedR': {'average': 28.0, 'std_dev': 0.0}, 'MeanR': {'average': 96.3, 'std_dev': 0.0}, 'geometric_mean_R1-R5-R10': {'average': 11.0, 'std_dev': 1.3}, 'MeanA': {'average': 0.1, 'std_dev': 0.0}}\n",
      "adv stats: {'R1': {'average': 59.0, 'std_dev': 14.3}, 'R3': {'average': 72.3, 'std_dev': 12.1}, 'R5': {'average': 78.4, 'std_dev': 10.5}, 'R10': {'average': 86.5, 'std_dev': 8.0}, 'R50': {'average': 96.9, 'std_dev': 2.4}, 'MedR': {'average': 1.5, 'std_dev': 0.9}, 'MeanR': {'average': 8.0, 'std_dev': 4.3}, 'geometric_mean_R1-R5-R10': {'average': 73.5, 'std_dev': 11.5}, 'MeanA': {'average': 0.1, 'std_dev': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the metrics from the file\n",
    "with open(f'{out_dir}/gt_metrics.pkl', 'rb') as f:\n",
    "    temp_gt_metrics = pkl.load(f)\n",
    "with open(f'{out_dir}/adv_metrics.pkl', 'rb') as f:\n",
    "    temp_adv_metrics = pkl.load(f)\n",
    "\n",
    "def post_analysis(data):\n",
    "    # Initialize dictionaries to hold lists of metric values across entries\n",
    "    metrics_before = {key: [] for key in data[0]['before']}\n",
    "\n",
    "    # Collect all metric values for each metric type across all entries\n",
    "    for entry in data.values():\n",
    "        for metric, value in entry['before'].items():\n",
    "            metrics_before[metric].append(value)\n",
    "\n",
    "    # Function to calculate mean and standard deviation\n",
    "    def calculate_stats(metrics_dict):\n",
    "        stats = {}\n",
    "        for metric, values in metrics_dict.items():\n",
    "            avg = round(np.mean(values), 1)\n",
    "            std_dev = round(np.std(values), 1)\n",
    "            stats[metric] = {'average': avg, 'std_dev': std_dev}\n",
    "        return stats\n",
    "\n",
    "    # Calculate stats for 'before' and 'after'\n",
    "    before_stats = calculate_stats(metrics_before)\n",
    "\n",
    "    return before_stats\n",
    "\n",
    "print(\"gt stats:\", post_analysis(temp_gt_metrics))\n",
    "print(\"adv stats:\", post_analysis(temp_adv_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the matrix\n",
    "with open(test_file_path, 'rb') as f:\n",
    "    matrix = pickle.load(f)\n",
    "\n",
    "# Transpose the matrix\n",
    "transposed_matrix = np.transpose(matrix)\n",
    "\n",
    "# Save the transposed matrix back to the original path\n",
    "with open(test_file_path, 'wb') as f:\n",
    "    pickle.dump(transposed_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the matrix\n",
    "with open(test_file_path, 'rb') as f:\n",
    "    matrix = pickle.load(f)\n",
    "\n",
    "# Transpose the matrix\n",
    "transposed_matrix = np.transpose(matrix)\n",
    "\n",
    "# Save the transposed matrix back to the original path\n",
    "with open(test_file_path, 'wb') as f:\n",
    "    pickle.dump(transposed_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_illusions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
